# ğŸ“š TechChallenge - API para Consulta de Livros

![FastAPI](https://img.shields.io/badge/FastAPI-v2.1.0-green)
![Python](https://img.shields.io/badge/Python-3.11-blue)
![Status](https://img.shields.io/badge/status-active-brightgreen)

---

## ğŸ” Sobre o Projeto

Esta API, construÃ­da com **FastAPI**, realiza web scraping no site [Books to Scrape](http://books.toscrape.com/) para coletar dados de livros, armazenÃ¡-los localmente em um arquivo `.csv` e disponibilizÃ¡-los via endpoints REST.

O objetivo principal Ã© demonstrar o fluxo completo de integraÃ§Ã£o entre coleta de dados (scraping), manipulaÃ§Ã£o e armazenamento, e disponibilizaÃ§Ã£o via API para consumo por cientistas de dados, desenvolvedores e demais interessados.

---

## âš™ï¸ Funcionalidades

- ğŸ“– Listar todos os livros ou filtrÃ¡-los por categoria.
- ğŸ” Buscar livros por tÃ­tulo e/ou categoria.
- ğŸ·ï¸ Listar todas as categorias disponÃ­veis.
- ğŸ†” Consultar um livro pelo seu ID Ãºnico.
- ğŸ©º Verificar o status da API e conectividade com o banco de dados.
- ğŸ’¾ Exportar dados completos para CSV (via geraÃ§Ã£o automÃ¡tica no backend).

## âš™ï¸ Requisitos

- Python 3.11+
- Git (opcional, para clonar o repositÃ³rio)

## ğŸ›  Tecnologias Utilizadas

| Tecnologia      | DescriÃ§Ã£o                              |
|-----------------|--------------------------------------|
| FastAPI         | Framework web moderno e rÃ¡pido       |
| Requests        | RequisiÃ§Ãµes HTTP para scraping       |
| BeautifulSoup4  | ExtraÃ§Ã£o de dados HTML                |
| Pandas          | ManipulaÃ§Ã£o e exportaÃ§Ã£o de dados    |
| Uvicorn         | Servidor ASGI para execuÃ§Ã£o da API   |
| Pydantic        | ValidaÃ§Ã£o de modelos e dados         |


---

## ğŸ“¥ InstalaÃ§Ã£o e ExecuÃ§Ã£o

- **Clonar o repositÃ³rio e entrar no diretÃ³rio:**
```bash
git clone https://github.com/devMansano/TechChallenge.git
cd TechChallenge

```

## ğŸ“ Estrutura do Projeto

```plaintext
TechChallenge/
â”œâ”€â”€ Main.py                # Arquivo principal que inicia a API FastAPI
â”œâ”€â”€ requirements.txt       # DependÃªncias do projeto
â”œâ”€â”€ books_complete.csv     # Banco de dados local gerado via scraping
â”œâ”€â”€ Scrapping/             # MÃ³dulo responsÃ¡vel pelo scraping e geraÃ§Ã£o do CSV
â”‚   â”œâ”€â”€ Scrap.py           # FunÃ§Ãµes para extrair categorias e livros do site
â”‚   â””â”€â”€ gera_base.py       # CriaÃ§Ã£o e leitura do CSV com os dados coletados
â”œâ”€â”€ Rota/                  # Endpoints da API organizados em mÃ³dulos
â”‚   â”œâ”€â”€ bem_vindo.py       # Rota raiz com mensagem de boas-vindas
â”‚   â”œâ”€â”€ book.py            # Rota para listagem geral de livros
â”‚   â”œâ”€â”€ categorias.py      # Rota para listar categorias disponÃ­veis
â”‚   â”œâ”€â”€ conexao.py         # Endpoint para checar saÃºde da API / status da base
â”‚   â””â”€â”€ id.py              # Busca de livro pelo ID
â”œâ”€â”€ Modelo/                # Modelos Pydantic para validaÃ§Ã£o de dados
â”‚   â””â”€â”€ Livro.py           # DefiniÃ§Ã£o do modelo Book
â””â”€â”€ README.md              # DocumentaÃ§Ã£o do projeto (este arquivo)

- **ğŸš€ Funcionalidades
- ğŸ“– Listar livros por categoria ou todos os disponÃ­veis.
- ğŸ” Buscar livros por tÃ­tulo e/ou categoria.
- ğŸ·ï¸ Listar categorias disponÃ­veis no site.
- ğŸ†” Consultar livro por ID.
- ğŸ’¾ Exportar todos os livros para CSV.
- ğŸ©º Verificar status de saÃºde da API.


**ğŸ› ï¸ Tecnologias Utilizadas**
- FastAPI â€” Framework web rÃ¡pido e moderno.
- Requests â€” RequisiÃ§Ãµes HTTP.
- BeautifulSoup4 â€” ExtraÃ§Ã£o de dados HTML.
- Pandas â€” ManipulaÃ§Ã£o e exportaÃ§Ã£o de dados.


**ğŸ“Œ Endpoints Principais**
MÃ©todo	Endpoint	DescriÃ§Ã£o

- GET	/	--> Mensagem de boas-vindas
- GET	/categories	--> Lista todas as categorias
- GET	/books -->	Lista todos os livros (ou filtra por categoria)
- GET	/api/v1/id/{Id} -->	Busca livro por ID
- GET	/api/v1/search?title=&category -->	Busca por tÃ­tulo e/ou categoria
- GET	/api/v1/health -->	Verifica status da API


**ğŸ“¤ Exportar para CSV**
- A funÃ§Ã£o export_csv() em Rota/Book.py coleta todos os livros do site e exporta para o arquivo books_complete.csv:


RepositÃ³rio GitHub:
https://github.com/devMansano/TechChallenge

**ğŸ“„ LicenÃ§a**
- Este projeto Ã© apenas para fins educacionais.
O site Books to Scrape Ã© destinado a prÃ¡ticas de web scraping e nÃ£o contÃ©m dados reais.